{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e989b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openreview\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as date\n",
    "import os\n",
    "import tqdm\n",
    "import ast\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import string\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "tqdm.tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e788aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rr_pairs_all = pd.read_csv('../data/model_inputs/df_sbert_rr_pairs_all.csv')\n",
    "\n",
    "df_rr_pairs_all=df_rr_pairs_all.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35389974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_x', 'type_x', 'invitation_x', 'readers_x', 'writers_x',\n",
       "       'signatures_x', 'title_x', 'comment_x', 'id_x', 'original_x',\n",
       "       'number_x', 'cdate_x', 'tcdate_x', 'tmdate_x', 'ddate_x', 'forum_x',\n",
       "       'referent_x', 'replyto_x', 'nonreaders_x', 'details_x', 'rating_x',\n",
       "       'review_x', 'confidence_x', 'year_y', 'type_y', 'invitation_y',\n",
       "       'readers_y', 'writers_y', 'signatures_y', 'title_y', 'comment_y',\n",
       "       'id_y', 'original_y', 'number_y', 'cdate_y', 'tcdate_y', 'tmdate_y',\n",
       "       'ddate_y', 'forum_y', 'referent_y', 'replyto_y', 'nonreaders_y',\n",
       "       'details_y', 'rating_y', 'review_y', 'confidence_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rr_pairs_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4925880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySentTokenize(texts):\n",
    "    # strip away splitters but sometimes formulas (more: +)\n",
    "    sents = [sent.strip(\" \\t*#=-_<>\") for parag in texts.split('\\n') for sent in sent_tokenize(parag)]\n",
    "    sents = [sent for sent in sents if sent]\n",
    "    \n",
    "    # fix i.e. e.g. and et al.\n",
    "    cleaned_sents = []\n",
    "    for sent in sents:\n",
    "        if cleaned_sents:\n",
    "            last_lc = cleaned_sents[-1].lower()\n",
    "            if last_lc.endswith('i.e.') or last_lc.endswith('ie.') or \\\n",
    "              last_lc.endswith('e.g.') or last_lc.endswith('eg.') or \\\n",
    "              (last_lc.endswith('et al.') and sent[0].islower()):\n",
    "                cleaned_sents[-1] += ' ' + sent\n",
    "                continue\n",
    "        cleaned_sents.append(sent)\n",
    "\n",
    "    # return [sent for sent in sents if len(word_tokenize(sent)) > 9]\n",
    "    # # eliminate single indicies but also 'Thanks!', 'Pros', 'Cons' and other section titles\n",
    "    # sents = [sent for sent in cleaned_sents if len([word for word in word_tokenize(sent) if word not in string.punctuation]) > 1]\n",
    "    sents = [sent for sent in cleaned_sents if len([word for word in word_tokenize(sent) if word not in string.punctuation]) > 9]\n",
    "    return [sent for sent in sents if not (sent[-1] == ':' and len(word_tokenize(sent)) <= 10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14cdc628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10435/10435 [00:32<00:00, 319.44it/s]\n",
      "100%|████████████████████████████████████| 10435/10435 [00:24<00:00, 431.56it/s]\n"
     ]
    }
   ],
   "source": [
    "df_rr_pairs_all['review_x_sent_tokens'] = df_rr_pairs_all['review_x'].progress_apply(lambda x: mySentTokenize(str(x)))\n",
    "df_rr_pairs_all['comment_y_sent_tokens'] = df_rr_pairs_all['comment_y'].progress_apply(lambda x: mySentTokenize(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86120155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forum_x</th>\n",
       "      <th>id_x</th>\n",
       "      <th>id_y</th>\n",
       "      <th>comment_y_sent_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r1Ue8Hcxg</td>\n",
       "      <td>rkeMJc-Ee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HJlgm-B9lx</td>\n",
       "      <td>SyHgRujVl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rJq_YBqxx</td>\n",
       "      <td>rJJHggGNx</td>\n",
       "      <td>BkSQh9u4e</td>\n",
       "      <td>[We have added an appendix that described the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rJq_YBqxx</td>\n",
       "      <td>rJJHggGNx</td>\n",
       "      <td>By45ECGEl</td>\n",
       "      <td>[We think our system is less complicated compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r1S083cgx</td>\n",
       "      <td>rJpkoyG4g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10430</th>\n",
       "      <td>HJePno0cYm</td>\n",
       "      <td>SJgjpKAko7</td>\n",
       "      <td>Hylxe2VcA7</td>\n",
       "      <td>[As shown in our paper, Transformer is the sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10431</th>\n",
       "      <td>H1g2NhC5KQ</td>\n",
       "      <td>H1lXb9okiX</td>\n",
       "      <td>rylhcb16TX</td>\n",
       "      <td>[To make the architecture clearer, we updated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10432</th>\n",
       "      <td>B1x9siCcYQ</td>\n",
       "      <td>r11pKi1i7</td>\n",
       "      <td>HJl2qAoFCQ</td>\n",
       "      <td>[We just would like to highlight a couple of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10433</th>\n",
       "      <td>HyGh4sR9YQ</td>\n",
       "      <td>HJg26wuJsX</td>\n",
       "      <td>HkeZ_0Dq07</td>\n",
       "      <td>[We are glad that you identify our paper as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10434</th>\n",
       "      <td>HylJtiRqYQ</td>\n",
       "      <td>SklWPtcC57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10435 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          forum_x        id_x        id_y  \\\n",
       "0       r1Ue8Hcxg   rkeMJc-Ee         NaN   \n",
       "1      HJlgm-B9lx   SyHgRujVl         NaN   \n",
       "2       rJq_YBqxx   rJJHggGNx   BkSQh9u4e   \n",
       "3       rJq_YBqxx   rJJHggGNx   By45ECGEl   \n",
       "4       r1S083cgx   rJpkoyG4g         NaN   \n",
       "...           ...         ...         ...   \n",
       "10430  HJePno0cYm  SJgjpKAko7  Hylxe2VcA7   \n",
       "10431  H1g2NhC5KQ  H1lXb9okiX  rylhcb16TX   \n",
       "10432  B1x9siCcYQ   r11pKi1i7  HJl2qAoFCQ   \n",
       "10433  HyGh4sR9YQ  HJg26wuJsX  HkeZ_0Dq07   \n",
       "10434  HylJtiRqYQ  SklWPtcC57         NaN   \n",
       "\n",
       "                                   comment_y_sent_tokens  \n",
       "0                                                     []  \n",
       "1                                                     []  \n",
       "2      [We have added an appendix that described the ...  \n",
       "3      [We think our system is less complicated compa...  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "10430  [As shown in our paper, Transformer is the sta...  \n",
       "10431  [To make the architecture clearer, we updated ...  \n",
       "10432  [We just would like to highlight a couple of t...  \n",
       "10433  [We are glad that you identify our paper as a ...  \n",
       "10434                                                 []  \n",
       "\n",
       "[10435 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rr_pairs_all[['forum_x','id_x','id_y','comment_y_sent_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "348d49a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10435it [2:38:04,  1.10it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../data/model_outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v9/8whxr3fd1mv_pwkjh0kn920m0000gn/T/ipykernel_95247/2096423871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#print(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdf_cos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdf_cos_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/model_outputs/df_cos_sim.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/bq/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3549\u001b[0m         )\n\u001b[1;32m   3550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3551\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3552\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3553\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/bq/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         )\n\u001b[0;32m-> 1180\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/bq/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \"\"\"\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/bq/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/bq/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../data/model_outputs'"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "for i, (rebuttal, review, forum) in tqdm.tqdm(df_rr_pairs_all[['comment_y_sent_tokens','review_x_sent_tokens','forum_x']].iterrows()):\n",
    "    input_row = {}\n",
    "    if rebuttal == []:\n",
    "        input_row['forum'] = forum\n",
    "        input_row['sim_score'] = 0\n",
    "        input_row['consine_scores'] = np.NaN\n",
    "        out.append(input_row)\n",
    "    else:\n",
    "        #Compute embedding for both lists\n",
    "        embeddings1 = model.encode(review, convert_to_tensor=True)\n",
    "        embeddings2 = model.encode(rebuttal, convert_to_tensor=True)\n",
    "\n",
    "        #Compute cosine-similarits\n",
    "        #todo find how to save all the embeddings with index of the sentences i guess\n",
    "        cosine_scores = util.cos_sim(embeddings1, embeddings2)        \n",
    "        max_cos_scores, y = torch.max(cosine_scores,dim=1)\n",
    "        input_row['consine_scores'] = cosine_scores\n",
    "        input_row['sim_score'] = torch.mean(max_cos_scores).item()\n",
    "        input_row['forum'] = forum\n",
    "        input_row['review'] = review\n",
    "        input_row['rebuttal'] = rebuttal\n",
    "        out.append(input_row)\n",
    "\n",
    "#print(out)\n",
    "df_cos_sim = pd.DataFrame(out)\n",
    "df_cos_sim.to_csv('../data/model_output/df_cos_sim.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4333a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cos_sim.to_csv('../data/model_output/df_cos_sim.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
